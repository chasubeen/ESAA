# **5. 데이터 전처리**
- ML 알고리즘은 데이터에 기반
  - 어떤 데이터를 입력으로 가지느냐에 따라 결과도 크게 달라질 수 있음
  - Garbage In, Garbage Out

- ML 알고리즘에서 전처리 사항들
  - 결손값(NaN, Null 등) 처리
    - 고정된 다른 값으로 변환
      - 평균값(피처 값 중 Null 값이 얼마 되지 않는 경우)
    - 대부분이 Null 값인 경우 해당 피처를 drop
  - 문자열 feature 처리
    - 사이킷런 ML 알고리즘은 오직 **숫자형** 변수만 처리 가능
    - 카테고리형 피처와 텍스트형 피처 처리
 
## **5-1. 데이터 인코딩**
### **a) 레이블 인코딩(Label Encoding)**
- 카테고리형 피처 -> 코드형 숫자 값(숫자형)
  - ex> ['사과', '바나나', '키위'] => [1,2,3] 
- ```LabelEncoder``` 클래스로 구현
```Python
from sklearn.preprocessing import LabelEncoder
```
- LabelEncoder 객체를 생성 후 ```fit()```, ```transform()```을 호출해 라벨 인코딩을 수행
- 문자열 값이 어떤 숫자 값으로 인코딩됐는지 확인하기 위해 LabelEncoder 객체의 ```classes_``` 속성값을 확인 가능
  - 0번부터 순서대로 변환된 인코딩 값에 대한 원본값을 가지고 있음
  - ```inverse_transform()```을 통해 인코딩된 값을 되돌릴 수 있음(디코딩)
- 레이블 인코딩의 경우 일괄적인 **숫자 값**으로 변환 -> 몇몇 ML 알고리즘에서 예측 성능 저하가 발생할 수 있음
  - 숫자 값의 크고 작음이 특성으로 작용하는 경우(선형 회귀 등)
  - 트리 계열의 알고리즘의 경우 숫자 값의 크고 작음에 영향 x -> 라벨 인코딩을 활용해도  ok
  - 이를 해결하기 위해 **원-핫 인코딩**을 활용 

### **b) 원-핫 인코딩(One - hot Encoding)**
- 피처 값의 유형에 따라 새로운 피처를 추가해 고유 값에 해당하는 칼럼에만 1을 표시하고 나머지 칼럼에는 0을 표시하는 방식
  - 행 형태로 되어 있는 피처의 고유 값을 **열 형태**로 차원을 변환한 뒤, 고유 값에 해당하는 칼럼에만 1을 표시하고 나머지 칼럼에는 0을 표시하는 방식

<img src = "https://user-images.githubusercontent.com/98953721/229297146-0b84a894-a9e1-4609-bcf3-1151b83b1f9b.png" width = 600 height = 300>

- 사이킷런의 ```OneHotEncoder```로 쉽게 변환 가능
```Python
from sklearn.model_preprocessing import OneHotEncoder
```

- 변환 절차
  1. 모든 문자열 값을 **숫자형** 값으로 변환
    - 주로 LabelEncoder를 활용
  2. 입력 값으로 **2차원 데이터**가 필요

<img src = "https://user-images.githubusercontent.com/98953721/229297554-37e8aa1c-0cba-4b7d-9b4c-90f4d5981f77.png" width = 800 height = 300>

- 판다스의 ```pd.get_dummies()```를 활용하면 해당 작업을 더 간단하게 처리할 수 있음
  - 문자열 카테고리 값을 숫자형으로 변환할 필요 없이 **바로** One-hot Encoding을 수행할 수 있음

## **5-2. 피처 스케일링과 정규화**
### **a) 피처 스케일링(feature scaling) 개요**
- 서로 다른 변수의 값 범위를 **일정한 수준**으로 맞추는 작업 
- 대표적인 방법으로 **표준화(Standardization)** 와 **정규화(Normalization)** 가 있음
  - 표준화
    - 데이터의 피쳐 값이 각각 평균 = 0, 분산 = 1인 **가우시안 정규 분포**를 가진 값으로 변환하는 것
    - ${x_{i}}{new} = \frac{x_{i}-mean(x)}{stdev(x)}$
  - 정규화
    - 서로 다른 피처의 크기를 **통일**하기 위해 크기를 변환해주는 개념
    - 개별 데이터의 크기를 모두 **똑같은** 단위로 변경하는 것
    - $x_{i}{new} = \frac{x_{i} - min(x)}{max(x) - min(x)}$  
    
  - 사이킷런의 ```Normalizer``` 모듈
    - 선형 대수에서의 정규화 개념이 적용됨 --> **벡터 정규화**  
    - 개별 벡터의 크기를 맞추기 위해 변환하는 것을 의미
      - 개별 벡터를 모든 피처 벡터의 크기로 나눠주는 작업
    - $x_{i}{new} = \frac{x_{i}}{\sqrt{x_{i}^2 + y_{i}^2 + z_{i}^2}}$
- Scaler 클래스의 ``fit()```, ```transform()```은 **2차원 이상**의 데이터에서만 가능
  - ```reshape()``` 메소드를 통해 2차원 이상의 데이터로 변환
  
### **b) 표준화(StandardScaler)**
- 사이킷런에서 구현한 RBF 커널을 이용하는 ```서포트 벡터 머신(Support Vector Machine)```, ```선형 회귀(LinearRegression)```, ```로지스틱 회귀(LogisticRegression)```은 데이터가 **가우시안 분포**를 가지고 있다고 가정하고 구현됨
  - 사전에 표준화를 적용하는 것이 예측 성능 향상에 중요한 영향을 미칠 수 있음
- 사이킷런의 ```StandardScaler``` 클래스를 활용  
```Python
from sklearn.preprocessing import StandardScaler
```
- StandardScaler 객체를 생성한 후에 ```fit()```과 ```transform()``` 메서드에 변환 대상 피처 데이터 세트를 입력하고 호출하여 표준화
  - 변환 후 반환되는 데이터는 ```np.ndarray```임

### **c) 정규화(MinMaxScaler)**
- 데이터 값을 0과 1 사이의 범위 값으로 변환
  - 음수가 있는 경우 -1에서 1 값으로 변환
- 데이터의 분포가 가우시안 분포가 아닐 때 적용 가능
- 사이킷런의 ```MinMaxScaler``` 클래스를 활용
```Python
from sklearn.preprocessing import MinMaxScaler
```
- MinMaxScaler 객체를 생성한 후에 ```fit()```과 ```transform()``` 메서드에 변환 대상 피처 데이터 세트를 입력하고 호출하여 표준화
  - 변환 후 반환되는 데이터는 ```np.ndarray```임

### **d) 스케일링 변환 시 유의점**
- Scaler 객체를 이용해 데이터의 스케일링 변환 시 ```fit()```, ```transform()```, ```fit_transform()``` 메소드를 활용
  - ```fit()```: 데이터 변환을 위한 기준 정보 설정(최대, 최소 등)
  - ```transform()```: 설정된 정보를 이용해 데이터를 변환
  - ```fit_transform()```: ```fit()```과 ```transform()```을 한번에 적용
- Scaler 객체를 이용해 학습 데이터 세트로 ```fit()```과 ```transform()```을 적용한 후 테스트 세트로는 다시 ```fit()```을 수행하지 **않고** ```transform()```을 적용해야 함
  - 학습 데이터로 ```fit()```이 적용된 스케일링 기준 정보를 **그대로** 테스트 데이터에 적용해야 함
  - 테스트 데이터로 다시 ```fit()```하면 스케일링 기준 정보가 **달라져** 올바른 예측 결과를 도출하지 못할 수 있음
  - ```fit_transform()```은 ```fit()```과 ```transform()```을 순차적으로 수행하는 메소드임
    - 학습 데이터에만 적용하고, 테스트 데이터에서는 사용하면 x
  - 따라서, 전체 데이터 세트에 대해 스케일링을 먼저 적용한 뒤 ```train_test_split()```을 해주는 편이 더 바람직함
    1. 가능하다면 전체 데이터의 스케일링 변환 -> 학습/테스트 데이터 분리
    2. 1이 힘들다면 테스트 데이터변환 시에는 ```fit()```이나 ```fit_transform()```을 사용하지 않고 학습 데이터로 이미 ```fit()```된 Scaler 객체를 이용해 ```transform()```만 적용
    
