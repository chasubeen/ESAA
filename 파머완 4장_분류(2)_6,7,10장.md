# **1. XGBoost**

### **1-1. XGBoost 개요**
- 트리 기반의 앙상블 학습에서 가장 각광받고 있는 알고리즘 중 하나
- 분류에 있어서 다른 머신러닝보다 뛰어난 예측 성능을 나타냄
- GBM 기반이지만, GBM의단점인 느린 수행 시간 및 과적합 규제 부재 등의 문제를 해결한 알고리즘
- 병렬 CPU환경에서의 병렬 학습을 지원하여 기존 GBM보다 빠른 학습 가능

<img src = "https://github.com/chasubeen/ESAA_8th_YB/assets/98953721/759071dc-5d32-4f2d-b432-6500b6eeb74c" width = 700 height = 150>

<img src = "https://github.com/chasubeen/ESAA_8th_YB/assets/98953721/52f75ffb-2ba9-4871-962f-7143d877066c" width = 700 height = 300>

### **1-2. XGBoost 설치**
- 파머완 p.228 ~ p.229

### **1-3. 파이썬 래퍼 XGBoost**
- 자체적으로 교차 검증, 성능 평가, 피처 중요도 등의 시각화 기능을 가지고 있음
- 조기 중단 기능이 O
- 병렬 처리 지원

#### **✅ 파이썬 래퍼 XGBoost 파라미터**
<img src = "https://github.com/chasubeen/ESAA_8th_YB/assets/98953721/9fe1fb0e-244b-4f8c-bf42-49d08ee80cfd" width = 1000 height = 1000>

<img src = "https://github.com/chasubeen/ESAA_8th_YB/assets/98953721/ad048ec2-903e-41ea-b3ee-f365be82cc94" width = 1000 height = 1000>

- ```일반``` 파라미터
	- 일반적으로 실행 시 스레드의 개수나 silent 모드 등의 선택을 위한 파라미터
  - 디폴트 파라미터 값을 바꾸는 경우는 거의 x
- ```부스터``` 파라미터: 트리 최적화, 부스팅, 규제(regularization) 등과 관련된 파라미터 등을 지칭
- ```학습 태스크``` 파라미터
	- 학습 수행 시의 객체 함수 
	- 평가를 위한 지표 등을 설정하는 파라미터

- 과적합 문제가 심각하다면 다음의 것들을 적용해 볼 수 있음
	- ```ela``` 값을 낮춤(0.01 ~ 0.1)
		- ```ela``` 값을 낮출 경우 ```num_round```(또는 ```n_estimators```)는 반대로 높여줘야 함
	- ```max_depth``` 값을 낮춤
	- ```min_child_weight``` 값을 높임
	- ```gamma``` 값을 높임
	- ```subsample```과 ```colsample_bytree```를 조정

---

- XGBoost에는 수행 속도를 향상시키기 위해 조기 중단(Early Stopping) 기능이 존재
	- ```n_estimators```에 지정한 부스팅 반복 횟수에 도달하지 않더라도 예측 오류가 더 이상 개선되지 않으면 반복을 끝까지 수행하지 않고 중지 -> 수행 시간 개선

- XGBoost 버전 확인
```Python
import xgboost

print(xgboost.__version__)
```  

- 사이킷런과 다르게 학습용과 테스트용 데이터 세트를 위해 별도의 객체인 **DMatrix** 를 생성함
	- 주로 넘파이 입력 파라미터를 받아서 만들어지는 XGBoost만의 전용 데이터 세트
	- 주요 입력 파라미터: data, label
	  - data: 피처 데이터 세트
	  - label: 분류는 레이블 데이터 세트, 회귀는 숫자형인 종속값 데이터 세트
	- DMatrix는 넘파이 외에 libsvm txt 포맷 파일, xgboost 이진 버퍼 파일 등을 파라미터로 입력받아 변환할 수 있음 
- xgboost 모듈에 내장된 ```plot_importance()```를 이용해 각 피처의 중요도를 시각화 할 수 있음
- ```to_graphviz()``` api를 이용하여 규칙 트리 구조를 그릴 수 있음
- 데이터 세트에 대한 교차 검증 수행 후 최적 파라미터를 구할 수 있는 방법을 ```cv()``` api로 제공
  - 반환값은 DataFrame 형태
   
<img src = "https://github.com/chasubeen/ESAA_8th_YB/assets/98953721/d47475ff-c914-4279-a2dc-38e108e6a63d" width = 600 height = 300>


### **1-4. 사이킷런 래퍼 XGBoost의 개요 및 적용**
- 사이킷런의 기본 Estimator를 그대로 상속해 만듦
  - 다른 Estimator와 동일하게 ```fit()```과 ```predict()```만으로 학습과 예측이 가능
  - GridSearchCV, Pipeline 등 사이킷런의 다른 유틸리티를 그대로 사용할 수 있음
- 분류를 위한 ```XGBClassifier```, 회귀를 위한 ```XGBRegressor```가 있음
- 조기 중단과 관련한 파라미터를 ```fit()```에 입력하여 조기 종료를 수행할 수 있음
  - ```early_stopping_rounds```: 평가 지표가 향상될 수 있는 반복 횟수
  - ```eval_metric```: 조기 중단을 위한 평가 지표
  - ```eval_set```: 성능 평가를 수행할 데이터 세트   
- 피처 중요도 시각화 가능

# **2. LightGBM**
- XGBoost와 함께 **부스팅** 계열 알고리즘에서 각광받고 있는 모델
- 장점
  - XGBoost보다 학습에 걸리는 시간이 훨씬 **적음**
  - 메모리 사용량이 적음
  - 카테고리형 피처의 자동 변환과 최적 분할(One-hot Encoding 등을 사용하지 않고도 카테고리형 피처를 최적으로 변환하고 이에따른 노드 분할 수행)
  - 대용량 데이터에 대한 뛰어난 예측 성능 및 병렬 컴퓨팅 기능을 제공하고 있음
    - 추가적으로 최근에는 GPU도 지원하고 있음 
- 단점
  - 적은 데이터 세트(일반적으로 10000건 이하의 데이터 세트)에 적용할 경우 과적합이 발생하기 쉬움
- 일반 GBM 계열의 트리 분할 방법과 다르게 **리프 중심 트리 분할(Leaf Wise)** 방식을 활용
  - 대부분은 트리의 깊이를 효과적으로 줄이기 위한 **균형 트리 분할(Level Wise)** 방식을 활용
  - 리프 중심 트리 분할 방식의 경우 트리의 균형을 맞추지 않고, 최대 손실 값(max delta loss)을 가지는 리프 노드를 지속적으로 분할하면서 트리의 깊이가 깊어지고 비대칭적인 규칙 트리를 생성함 
  - 최대 손실값을 가지는 리프 노드를 지속적으로 분할해 생성된 규칙 트리는 학습을 반복할수록 결국은 균형 트리 분할 방식보다 예측 오류 손실을 최소화 할 수 있다는 것이 LightGBM의 구현 사상

<img src = "https://github.com/chasubeen/ESAA_8th_YB/assets/98953721/a2ca08fb-6ce9-40be-836c-640c29690a49" width = 500 height = 150>


### **2-1. LightGBM 설치**
- 파머완 p.246 ~ 247

### **2-2. LightGBM 하이퍼 파라미터**
- LightGBM은 XGBoost와 다르게 리프 노드가 계속 **분할**되면서 트리의 깊이가 깊어지므로 이러한 트리 특성에 맞는 하이퍼 파라미터 설정이 필요하다는 점
  - 예) ```max_depth```를 매우 크게 가짐

#### **주요 파라미터**  
- ```num_iterations(default = 100)```
  - 반복 수행하려는 트리의 개수를 지정
  - 크게 지정할수록 예측 성능이 높아질 수 있으나, 너무 크게 지정하면 오히려 과적합으로 성능이 저하될 수 있음
  - 이후 사이킷런 호환 클래스에서는 ```n_estimators```로 이름이 변경됨 
- ```learning_rate(default = 0.1)```
  - 0에서 1 사이의 값을 지정하며 부스팅 스텝을 반복적으로 수행할 때 업데이트되는 학습률 값
  - 일반적으로 ```n_estimators```를 **크게** 하고 ```learning_rate```를 **작게** 해서 예측 성능을 향상시킬 수 있으나, 마찬가지로 과적합 이슈와 학습 시간이 길어지는 부정적인 영향 또한 고려해야 함
- ```max_depth(default = -1)```
  - 트리 기반 알고리즘의 ```max_depth```와 동일
  - 0보다 작은 값을 지정하면 깊이에 제한이 없음
  - Depth Wise 방식의 트리와 다르게 LightGBM은 Leaf Wise 기반이므로 깊이가 상대적으로 더 깊음
- ```min_data_in_leaf(default = 20)```
  - 결정 트리의 ```min_samples_leaf```와 같은 파라미터
  - 최종 결정 클래스인 리프 노드가 되기 위해서 최소한으로 필요한 레코드 수
  - 과적합을 제어하기 위한 파라미터
- ```num_leaves(default = 31)```
  - 하나의 트리가 가질 수 있는 최대 리프 개수 
- ```boosting(default = gbdt)```
  - 부스팅의 트리를 생성하는 알고리즘을 기술 
  - gbdt: 일반적인 그래디언트 부스팅 결정 트리
  - rf: 랜덤 포레스트
- ```bagging_fraction(default = 1.0)```
  - 트리가 커져서 과적합되는 것을 제어하기 위해서 데이터를 샘플링하는 비율을 지정
- ```feature_fraction(default = 1.0)```
  - 개별 트리를 학습할 때마다 무작위로 선택하는 feature의 비율
  - 과적합을 막기 위해 사용됨 
- ```lambda_l2(default = 0.0)```
  - L2 규제를 위한 값 
  - 피처 개수가 많을 경우 적용을 검토하며 값이 클수록 과적합 감소 효과가 있음
- ```lambda_l1(default = 0.0)```
  - L1 규제 제어를 위한 값
  - L2와 마찬가지로 과적합 제어를 위한 것

### **2-3. Learning Task 파라미터**
- ```objective```
  - 최솟값을 가져야 할 손실함수를 정의
  - XGBoost의 objective 파라미터와 동일
  - 애플리케이션 종류(회귀, 다중 클래스 분류, 이진 분류)에 따라 objective인 손실함수가 지정됨 

### **2-4. 하이퍼 파라미터 튜닝 방안**
- ```num_leaves``` 개수를 중심으로 ```min_child_samples(min_data_in_leaf)```, ```max_depth```를 함께 조정하면서 모델의 복잡도를 줄이는 방향이 기본 튜닝 방안임
  - 일반적으로 ```num_leaves```의 개수를 높이면 정확도가 높아지지만, 반대로 트리의 깊이가 깊어지고 모델이 복잡도가 커져 과적합 영향도가 커짐
  - ```min_child_samples```는  ```num_leaves```와 학습 데이터의 크기에 따라 달라지지만, 보통 큰 값으로 설정하면 트리가 깊어지는 것을 방지
  - ```max_depth```는 명시적으로 깊이의 크기를 제한함
- 모두 과적합을 개선하는 데 활용됨
- 이외에도 ```reg_lambda```, ```reg_alpha```와 같은 정규화를 적용하거나 학습 데이터에 사용할 피처의 개순나 데이터 샘플링 레코드 갯구를 줄이기 위해 ```colsample_bytree```, ```subsample``` 파라미터를 적용할 수 있음

### **2-5. 파이썬 래퍼 LightGBM vs 사이킷런 래퍼 XGBoost, LightGBM 하이퍼 파라미터 비교**

<img src = "https://github.com/chasubeen/ESAA_8th_YB/assets/98953721/ddd4bc4f-cc49-45cc-be4f-71b48d32fba6" width = 800 height = 350>


# **3. 스태킹 앙상블**
### **3-1. 스태킹(stacking)**
- 개별 알고리즘의 예측 결과 데이터 세트를 최종적인 메타 데이터 세트로 만들어 별도의 ML 알고리즘으로 최종 학습을 수행하고 테스트 데이터를 기반으로 다시 최종 예측을 수행하는 방식(**메타 모델**)
- 개별적인 여러 알고리즘을 서로 결합해 예측 결과를 도출
- **두 종류의 모델** 을 필요로 함
  - 개별적인 기반 모델
  - 최종 메타 모델
    - 개별 기반 모델의 예측 데이터를 학습 데이터로 만들어서 학습
- ⭐ 여러 개별 모델의 예측 데이터를 각각 스태킹 형태로 결합해 최종 메타 모델의 학습용 피처 데이터 세트와 테스트용 피처 데이터 세트를 만드는 것
  - 일반적으로 성능이 **비슷한** 모델을 결합   
- 많은 개별 모델을 필요로 함 -> 현실에서는 많이 사용되지 x   

<img src = "https://github.com/chasubeen/ESAA_8th_YB/assets/98953721/06c69c7a-3dde-4a97-ab0f-c6d6841700c1" width = 400 height = 400>

### **3-2. 기본 스태킹 모델**
- M개의 로우, N개의 피처(칼럼)을 가진 데이터 세트에 스태킹 앙상블을 적용한다고 가정

<img src = "https://github.com/chasubeen/ESAA_8th_YB/assets/98953721/132aa0b0-8da8-492c-b6d7-4a1028cba839" width = 700 height = 300>

1. 모델별로 각각 학습을 시킨 뒤 예측을 수행하면 각각 M개의 로우를 가진 1개의 레이블 값이 도출됨
2. 모델별로 도출된 예측 레이블 값을 다시 합해서(**스태킹**) 새로운 데이터 세트를 만들고, 이렇게 스태킹된 데이터 세트에 대해 최종 모델을 적용해 최종 예측을 수행

### **3-3. CV 세트 기반의 스태킹**
- 최종 메타 모델을 위한 데이터 세트를 만들 때 교차 검증 기반으로 예측된 결과 데이터 세트를 활용
	- 과적합 개선
- 개별 모델들이 각각 교차 검증으로 메타 모델을 위한 학습용 스태킹 데이터 생성과 예측을 위한 테스트용 스태킹 데이터를 생성한 뒤 이를 기반으로 메타 모델이 학습/예측 수행
  - Step 1. 각 모델별로 원본 학습/테스트 데이터를 예측한 결과 값을 기반으로 메타 모델을 위한 학습용/테스트용 데이터를 생성
  - Step 2. 스텝 1에서 개별 모델들이 생성한 학습용/테스트용 데이터를 모두 스태킹 형태로 합쳐서 메타 모델이 학습할 최종 학습용/테스트용 데이터 세트를 생성
    - 메타 모델은 최종적으로 생성된 학습 데이터 세트와 원본 학습 데이터의 레이블 데이터를 기반으로 학습한 뒤, 최종적으로 생성된 테스트 데이터 세트를 예측하고, 원본 테스트 데이터의 레이블 데이터를 기반으로 평가

<img src = "https://github.com/chasubeen/ESAA_8th_YB/assets/98953721/9fe4f177-891b-45cf-83f4-ee9e97d226b8" width = 700 height = 450>

#### **📌 단계별 설명**
**[Step 1]**  
- 첫 번째 반복
<img src = "https://github.com/chasubeen/ESAA_8th_YB/assets/98953721/f4801675-9231-49d0-9685-854965b0a1dc" width = 700 height = 300>

  - 학습용 데이터를 N개의 폴드(fold)로 나누되, (N-1)개 폴드는 **학습** 을 위한 데이터로, 나머지 1개의 폴드는 **검증** 을 위한 데이터 폴드로 나눔 -> 학습 데이터로 개별 모델 학습
  - 학습된 개별 모델을 검증 폴드 1개로 예측 -> 결과 저장 -> 메타 모델을 학습시키는 학습 데이터로 활용
  - (N-1)개의 **학습** 폴드 데이터로 학습된 개별 모델은 원본 테스트 데이터를 예측하여 예측값을 생성
    - 해당 로직을 N번 반복하며 해당 예측값의 평균으로 최종 결괏값을 생성하고 이를 메타 모델을 위한 테스트 데이터로 활용
    
- 두 번째 반복
  - 폴드 내의 학습용 데이터 세트만 변경하여 첫번째 반복과 같은 작업 수행

- 세 번째 반복
  - 폴드 내의 학습용 데이터 세트만 변경하여 첫번째, 두번째 반복과 같은 작업 수행
  - 마지막 반복을 완료하면 각 반복을 수행하면서 만들어진 폴드별 예측 데이터를 합하여 메타 모델에서 사용될 학습 데이터 생성
  - 마찬가지로 각 반복을 수행하면서 학습 폴드 데이터로 학습된 개별 모델이 원본 테스트 세트로 예측한 결괏값을 최종 **평균** 하여 메타 모델에서 사용될 테스트 데이터를 생성함

<img src = "https://github.com/chasubeen/ESAA_8th_YB/assets/98953721/cb433cab-9cfd-4d7b-b130-0b99f506f4c6" width = 700 height = 300>

**[Step 2]**  
- 각 모델들이 Step 1로 생성한 학습/테스트 데이터를 모두 합쳐 최종적으로 메타 모델이 사용할 학습/테스트 데이터 생성
- 메타 모델이 사용할 최종 학습 데이터와 원본 데이터의 레이블 데이터를 합쳐서 메타 모델을 학습 한 후에 최종 테스트 데이터로 예측을 수행한 뒤, 최종 예측 결과를 원본 테스트 데이터의 레이블 데이터와 비교/평가

