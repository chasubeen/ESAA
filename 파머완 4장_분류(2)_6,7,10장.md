# **1. XGBoost**

# **2. LightGBM**
- XGBoost와 함께 **부스팅** 계열 알고리즘에서 각광받고 있는 모델
- 장점
  - XGBoost보다 학습에 걸리는 시간이 훨씬 **적음**
  - 메모리 사용량이 적음
- 단점
  - 적은 데이터 세트(일반적으로 10000건 이하의 데이터 세트)에 적용할 경우 과적합이 발생하기 쉬움
- 일반 GBM 계열의 트리 분할 방법과 다르게 **리프 중심 트리 분할(Leaf Wise)** 방식을 활용
  - 대부분은 트리의 깊이를 효과적으로 줄이기 위한 **균형 트리 분할(Level Wise)** 방식을 활용
  - 리프 중심 트리 분할 방식의 경우 트리의 균형을 맞추지 않고, 최대 손실 값(max delta loss)을 가지는 리프 노드를 지속적으로 분할하면서 트리의 깊이가 깊어지고 비대칭적인 규칙 트리를 생성함 



































