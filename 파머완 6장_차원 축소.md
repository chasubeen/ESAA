# **1. 차원 축소(Dimension Reduction)**
### **1-1. 차원 축소**
- 매우 많은 피처로 구성된 다차원 데이터 세트의 차원을 축소해 새로운 차원의 데이터 세트의 차원을 축소해 새로운 차원의 데이터 세트를 생성하는 것
- 일반적으로 차원이 증가할수록 데이터 포인트 간의 거리가 기하급수적으로 멀어지게 되고, **희소(sparse)** 한 구조를 가지게 됨
  - 수백 개 이상의 피처로 구성된 데이터 세트의 경우 상대적으로 적은 차원에서 학습된 모델보다 예측 신뢰도가 떨어짐
- 피처가 많을 경우 개별 피처 간에 상관관계가 **높을** 가능성이 큼
  - 선형 회귀 등 **선형** 모델에서는 입력 변수 간의 상관관계가 높을 경우 이로 인한 다중공선성 문제로 모델의 예측 성능이 저하됨  
- 효과
  - 매우 많은 다차원의 피처를 차원 축소해 피처 수를 줄이면 더 **직관적**으로 데이터를 해석할 수 있음
  - 차원 축소 시 학습 데이터의 크기가 줄어들어서 학습에 필요한 처리 능력을 줄일 수 있음

### **1-2. 차원 축소의 종류**
#### **a) 피처 선택(feature selection)**  
- 특정 피처에 종속성이 강한 불필요한 피처는 아예 제거하고, 데이터의 특징을 잘 나타내는 주요 피처만 선택하는 것 
#### **b) 피처 추출(feature extraction)**  
- 기존 피처를 저차원의 중요 피처로 압축해서 추출하는 것
  - 피처를 함축적으로 더 잘 설명할 수 있는 또 다른 공간으로 매핑해 추출하는 것
  - 기존 피처가 전혀 인지하기 어려웠던 **잠재적인 요소** (Latent Factor)를 추출하는 것 
- 새롭게 추출된 중요 특성은 기존의 피처가 압축된 것이므로 기존의 피처와는 완전히 다른 값

### **1-3. 차원 축소 활용**
#### **a) 이미지 데이터**
- 잠재된 특성을 피처로 도출해 함축적 형태의 이미지 변환과 압축을 수행할 수 있음
- 변환된 이미지는 원본 이미지보다 훨씬 **적은** 차원
  - 이미지 분류 등의 분류 수행 시 과적합 영향력이 작아져서 오히려 원본 데이터로 예측하는 것보다 예측 성능을 더 끌어 올릴 수 있음 
#### **b) 텍스트 분석**
- 텍스트 문서의 숨겨진 의미 추출
- 문서 내 단어들의 구성에서 숨겨져 있는 시맨틱(semantic) 의미나 토픽(topic)을 잠재 요소로 간주하고 이를 찾아낼 수 있도록 함
- SVD, NMF 등이 존재함


































































