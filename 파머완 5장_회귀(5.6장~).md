# **7. 로지스틱 회귀**
- 선형 회귀 방식을 **분류**에 적용한 알고리즘
  - 이름은 회귀지만 사실은 **분류** 알고리즘
- 회귀가 선형인가 비선형인가는 독립변수가 아닌 **가중치 변수(weight)** 가 선형인지 아닌지를 따름
  - 학습을 통해 선형 함수의 회귀 최적선을 찾는 것이 아니라 ```시그모이드(sigmoid)``` 함수 최적선을 찾고, 이 시그모이드 함수의 반환 값을 확률로 간주해 확률에 따라 분류를 결정하는 것 
- 선형 회귀 방식을 기반으로 하되 시그모이드 함수를 이용해 **분류**를 수행하는 회귀 방식
- 가볍고 빠름
- **이진** 분류 예측 성능이 뛰어나고, 희소한 데이터 세트 분류에도 뛰어난 성능을 보임

<img src = "https://github.com/chasubeen/ESAA_8th_YB/assets/98953721/d53ea33b-8e8c-44c5-ade1-d758f7d25d68" width = 400 height = 200>

- ```시그모이드 함수```
  - S자 커브 형태를 가짐
  - 정의) $y = \frac{1} {1+{e}^{-x}}$ 
  - y값은 항상 0과 1 사이 값을 반환함
  
- 주요 파라미터
  - ```penalty```
    - 규제(regularization)의 유형 설정 
    - 'l2'로 설정 시 L2 규제, 'l1'로 설정 시 L1 규제를 적용
    - default: 'l2'
  - ```C```
    - 규제 강도를 조절하는 alpha 값의 역수
    - 작을수록 규제 강도가 큼
    




















