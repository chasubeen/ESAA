# **6. 규제 선형 모델 - 릿지, 라쏘, 엘라스틱넷**

### **6-1. 규제 선형 모델의 개요**
- 회귀 모델은 적절히 데이터에 적합하면서도 회쉬 계수가 기하급수적으로 커지는 것을 제어할 수 있어야 함
- 비용 함수는 학습 데이터의 잔차 오류 값을 최소로 하는 ```RSS 최소화``` 방법과 과적합을 방지하기 위해 ```회귀 계수 값이 커지지 않도록``` 하는 방법이 균형을 이뤄야 함
	- 비용 함수 목표: MIN($RSS(W) + alpha * \parallel W\parallel_{2}^{2}$)
- ```alpha```
	- 학습 데이터 적합 정도와 회귀 계수 값의 크기 제어를 수행하는 튜닝 파라미터
	- alpha 값을 크게 하면 비용 함수는 회귀 계수 w의 값을 작게 해 과적합을 개선할 수 있으며 alpha 값을 작게 하면 회귀 계수 w의 값이 커져도 어느 정도 상쇄가 가능하므로 학습 데이터 적합을 더 개선할 수 있음
- 규제(Regularization): 비용 함수에 alpha 값으로 페널티를 부여해 회귀 계수 값의 크기를 감소시켜 과적합을 개선하는 방식
	- ```L2 방식```: $alpha * \parallel W\parallel_{2}^{2}$ 와 같이 W의 재곱에 대해 페널티를 부여하는 방식, **릿지(Ridge)**
	- ```L1 방식```: $alpha * \parallel W\parallel_{1}$ 와 같이 W의 절댓값에 대해 패널티를 부여하는 방식, **라쏘(Lasso)**
		- L1 규제 적용 시 영향력이 크지 않은 회귀 계수는 0이 됨 

### **6-2. 릿지 회귀**
- ```sklearn.Ridge``` 클래스를 통해 구현
- 주요 파라미터
	- ```alpha```: L2 규제 계수
- alpha 값을 계속 증가시킬수록 회귀 계수 값은 지속적으로 작아짐
	- 그러나 릿지 회귀의 경우에는 회귀 계수를 0으로 만들지는 않음

### **6-3. 라쏘(Lasso) 회귀**
- L1 규제를 선형 회귀에 적용한 것
	- W의 절댓값에 페널티 부여 
- 불필요한 회귀 계수를 급격하게 감소시켜 0으로 만들고 제거
	- 적절한 피처만 회귀에 포함시키는 **피처 선택**의 특성을 지님
- ```sklearn.Lasso```를 통해 구현
- 주요 파라미터
	- ```alpha```: L1 규제 계수
- alpha 값을 계속 증가시킬수록 회귀 계수 값은 지속적으로 작아짐
	- 라쏘 회귀의 경우에는 일부 피처의 회귀 계수를 아예 0으로 만듦

### **6-4. 엘라스틱넷 회귀(ElasticNet)**
- L2 규제 + L1 규제
	- 비용함수의 목표: $RSS(W) + alpha2 * \parallel W\parallel_{2}^{2} + alpha1 * \parallel W\parallel_{1}$ 를 최소화하는 W 찾기
- 라쏘 회귀의 경우 서로 상관관계가 높은 피처들의 경우에 이들 중에서 중요 피처만을 셀렉션하고 다른 피처들은 모두 회귀 계수를 0으로 만드는 성향이 강함
	- alpha 값에 따른 회귀 계수의 값이 급변함
	- 엘라스틱넷은 이를 완화하기 위해 L2 규제를 라쏘 회귀에 추가한 것
- 수행 시간이 오래 걸린다는 단점은 존재
- ```sklearn.ElasticNet```을 통해 구현
- 주요 파라미터
	- ```alpha```
		- 엘라스틱넷의 규제: a * L1 + b * L2
		- ElasticNet의 alpha = a + b 
	- ```l1_ratio``` 
		- a / (a + b) 
		- 0이면 a가 0이므로 **L2 규제** 와 동일
		- 1이면 b가 0이므로 **L1 규제** 와 동일

### **6-5. 선형 회귀 모델을 위한 데이터 변환**
- 선형 회귀 모델과 같은 선형 모델은 일반적으로 피처와 타깃값 간에 **선형**의 관계가 있다고 가정하고, 이러한 최적의 선형함수를 찾아내 결과값을 예측함
- 또한 선형 회귀 모델은 피처값과 타깃값의 분포가 **정규 분포 형태** (평균을 중심으로 종 모양으로 데이터 값이 분포된 형태)를 매우 선호함
	- 타깃값의 경우 정규 분포 형태가 아니라 특정값의 분포가 치우친 왜곡(skew)된 형태의 분포도일 경우 예측 성능에 부정적인 영향을 미칠 수 있음
- 선형 회귀 모델을 적용하기 전에 먼저 데이터에 대한 ```스케일링/정규화``` 작업을 수행하는 것이 일반적임

#### **✔ 데이터 변환 방법**
1. ```StandardScaler``` 클래스: 표준화, 평균이 0이고 분산이 1인 표준 정규 분포를 가진 데이터 세트로 변환
2. ```MinMaxScaler``` 클래스: 정규화, 최솟값이 0이고 최댓값이 1이 되도록 변환
3. 스케일링. 정규화를 수행한 데이터 세트에 다시 ```다항 특성```을 적용하여 변환하는 방법
	- 1,2 적용 후 예측 성능에 향상이 없을 경우 이와 같은 방법을 시도
	- 다항 변환으로 생성되는 피처의 개수가 기하급수로 늘어 과적합 이슈가 발생할 수 있음
4. 원래 값에 ```log 함수``` 를 적용(로그 변환)
	- 보다 정규 분포에 가까운 형태로 분포 변환
	- 많이 사용되는 변환 방법

- ```target``` 변수의 경우 일반적으로는 **로그 변환** 을 수행
	- 결정 값을 정규 분포나 다른 정규값으로 변환 시 변환된 값을 다시 원본 타깃값으로 원복하기 어려울 수 있음  

# **7. 로지스틱 회귀**
- 선형 회귀 방식을 **분류**에 적용한 알고리즘
  - 이름은 회귀지만 사실은 **분류** 알고리즘
- 회귀가 선형인가 비선형인가는 독립변수가 아닌 **가중치 변수(weight)** 가 선형인지 아닌지를 따름
  - 학습을 통해 선형 함수의 회귀 최적선을 찾는 것이 아니라 ```시그모이드(sigmoid)``` 함수 최적선을 찾고, 이 시그모이드 함수의 반환 값을 확률로 간주해 확률에 따라 분류를 결정하는 것 
- 선형 회귀 방식을 기반으로 하되 시그모이드 함수를 이용해 **분류**를 수행하는 회귀 방식
- 가볍고 빠름
- **이진** 분류 예측 성능이 뛰어나고, 희소한 데이터 세트 분류에도 뛰어난 성능을 보임

<img src = "https://github.com/chasubeen/ESAA_8th_YB/assets/98953721/d53ea33b-8e8c-44c5-ade1-d758f7d25d68" width = 400 height = 200>

- ```시그모이드 함수```
  - S자 커브 형태를 가짐
  - 정의) $y = \frac{1} {1+{e}^{-x}}$ 
  - y값은 항상 0과 1 사이 값을 반환함
  
- 주요 파라미터
  - ```penalty```
    - 규제(regularization)의 유형 설정 
    - 'l2'로 설정 시 L2 규제, 'l1'로 설정 시 L1 규제를 적용
    - default: 'l2'
  - ```C```
    - 규제 강도를 조절하는 alpha 값의 역수
    - 작을수록 규제 강도가 큼
    
# **8. 회귀 트리**
- 트리 기반 회귀: 회귀 **트리** 를 이용하는 것
	- 회귀를 위한 트리를 생성하고 이를 기반으로 회귀 예측을 수행하는 것
	- 리프 노드에 속한 데이터 값의 **평균값** 을 구해 회귀 예측값을 계산
- X 값의 균일도를 반영한 ```지니 계수```에 따라 분할

<img src = "https://github.com/chasubeen/ESAA_8th_YB/assets/98953721/8f94f387-51b4-4c3b-8572-5681d3109ffa" width = 500 height = 250>

- ```CART```(Classification And Regression Trees) 기반 트리 생성
- 사이킷런의 트리 기반 ```Estimator 클래스```  

|알고리즘|회귀 Estimator 클래스|분류 Estimator 클래스|  
|-------|----------|----------|
|Decision Tree|DecisionTreeRegressor|DecisionTreeClassifier|
|Gradient Boosting|GradientBoostingRegressor|GradientBoostingClassifier|
|XGBoost|XGBRegressor|XGBClassifier|
|LightGBM|LGBMRegressor|LGBMClassifier|

















