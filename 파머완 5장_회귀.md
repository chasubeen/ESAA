# **1. 회귀 소개**
### **📌 회귀(regression)**
- 데이터 값이 평균과 같은 일정한 값으로 **돌아가려는** 경향을 이용한 통계학 기법
- 여러 개의 ```독립변수(X)```와 한 개의 ```종속변수(y)``` 간의 상관관계를 모델링하는 기법을 통칭
  - ML 관점에서 독립변수는 **피처**, 종속변수는 **결정 값**에 해당 
- ```회귀 계수(intercept)```: W1, W2, W3, ... / 독립변수의 값에 영향을 미치는 것들
- 머신러닝 회귀 예측의 핵심은 주어진 피처와 결정 값 데이터 기반에서 학습을 통해 **최적의 회귀 계수**를 찾아내는 것
- 회귀는 회귀 계수의 선형/비선형 여부, 독립변수의 개수, 종속변수의 개수에 따라 여러 가지 유형으로 나눌 수 있음
  - 회귀 계수의 선형 여부에 따라 **선형 회귀**와 **비선형 회귀**로 나눌 수 있음
  - 독립변수의 개수에 따라 **단일 회귀**와 **다중 회귀**로 나눌 수 있음  

### **📌 선형 회귀**
- 여러 가지 회귀 중에서 선형 회귀가 가장 많이 사용됨
- 선형 회귀는 실제 값과 예측값의 **차이**(오류의 제곱값)를 최소화하는 직선형 회귀선을 최적화하는 방식
- **규제(Regularization)** 방법에 따라 다시 별도의 유형으로 나눌 수 있음
  - 규제: 일반적인 선형 회귀의 과적합 문제를 해결하기 위해서 회귀 계수에 패널티 값을 적용하는 것
- **대표적인 선형 회귀 모델**  
  - ```일반 선형 회귀```
    - 예측값과 실제 값의 RSS(Residual Sum of Squares)를 최소화 할 수 있도록 회귀 계수를 최적화
    - 규제 적용 x
  - ```릿지(Ridge)```
    - 선형 회귀에 L2 규제를 추가한 회귀 모델
    - L2 규제를 적용
    - L2 규제: 상대적으로 큰 회귀 계수 값의 예측 영향도를 감소시키기 위해 회귀 계수값을 더 작게 만드는 규제 모델
  - ```라쏘(Lasso)```
    - 선형 회귀에 L1 규제를 적용한 방식
    - L1 규제: 예측 영향력이 작은 피처의 회귀 계수를 0으로 만들어 회귀 예측 시 피처가 선택되지 않게 하는 방식
  - ```엘라스틱넷(ElasticNet)```
    - L2, L1 규제를 함께 결합한 모델
    - 주로 피처가 많은 데이터 세트에서 적용됨
    - L1 규제로 피처의 개수를 줄임과 동시에 L2 규제로 계수 값의 크기를 조정함
  - ```로지스틱 회귀(Logistic Regression)```
    - 사실은 분류 모델
    - 일반적으로 이진 분류뿐만 아니라 최소 영역의 분류 등에서도 뛰어난 예측 성능을 보임  

# **2. 단순 선형 회귀를 통한 회귀 위해**
- 독립변수도 하나, 종속변수도 하나인 선형 회귀

<img src = "https://github.com/chasubeen/ESAA_8th_YB/assets/98953721/a7912b47-0e08-48ca-a844-bd8c1220d02c" width = 400 height = 300>

- 최적 회귀 모델은 **잔차**(실제 값 - 예측값)를 최소화하는 모델, 즉 오류값의 합이 최소가 되는 **최적의 회귀 계수**를 찾는 것을 의미
  - 오류 값은 양수/음수 둘 다 가능 => 주로 절댓값을 취해 더하거나(**MSE**), 오류 값의 제곱을 구해서 더하는 방식(**RSS**)을 택함
  - 일반적으로 미분 등의 계산을 편리하게 하기 위해서 **RSS** 방식을 택함
  
<img src = "https://github.com/chasubeen/ESAA_8th_YB/assets/98953721/b124f81e-39da-4773-b3f2-3c1c53d22daa" width = 400 height = 200>    

- 머신러닝 기반 회귀는 최적의 회귀 계수를 학습을 통해서 찾는 것이 핵심임
  - RSS는 회귀식의 독립변수 X, 종속변수 Y가 중심 변수가 아니라 **w 변수(회귀 계수)**가 중심 변수임
  - 일반적으로 RSS는 학습 데이터의 건수로 나누어서 다음과 같이 정규화된 식으로 표현됨
  $$RSS(w_{0},w_{1}) = \frac{1}{N}\sum_1^N (y_{i}-(w_{0}+w_{1}*x_{i}))^2$$
  
  - 회귀에서 RSS는 **비용(cost)** 이며 w 변수(회귀 계수)로 구성됨
    - **비용 함수**를 지속해서 감소시키고 최종적으로는 더 이상 감소하지 않는 최소의 오류 값을 구하는 것이 핵심



















