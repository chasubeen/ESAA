# **1. 사이킷런 소개와 특징**
### **1-1. 사이킷런(scikit-learn)**
- 파이썬 머신러닝 라이브러리 중 가장 많이 사용되는 라이브러리
- 특징
  - 가장 파이썬스러운 API
  - 머신러닝을 위한 매우 다양한 알고리즘과 개발을 위한 편리한 프레임워크와 API 제공
  - 오랜 기간 실전 환경에서 검증되었으며, 매우 많은 환경에서 사용되는 성숙한 라이브러리
- 사이킷런 설치
```Python
conda install scikit-learn

또는 

pip install scikit-learn
```

- 사이킷런 버전 확인
```Python
print(sklearn.__version__)
```

- 사이킷런 내의 데이터 불러오기
  - ```sklearn.model_selection```
  - 학습 데이터와 검증 데이터, 예측 데이터로 데이터를 분리하거나 최적의 하이퍼 파라미터로 평가하기 위한 다양한 모듈의 모임
    - 하이퍼 파라미터
      - 머신러닝 알고리즘별로 최적의 학습을 위해 직접 입력하는 파라미터
      - 하이퍼 파라미터를 통해 머신러닝 알고리즘의 성능을 튜닝할 수 있음
       
- ```sklearn.tree```를 통해 트리 기반 ML 알고리즘을 가져올 수 있음

# **2. 첫 번째 머신러닝 만들어 보기 - 붓꽃 품종 예측하기**
### **2-0. Introduction**
- 목표: 붓꽃 데이터 세트로 붓꽃의 품종을 **분류(classification)**하는 것
- 꽃잎의 길이와 너비, 꽃받침의 길이와 너비 피처를 기반으로 꽃의 품종을 예측

### **2-1. 분류(Classification)**
- 대표적인 **지도학습(supervised-learning)** 방법의 하나
  - 학습을 위한 다양한 피처와 분류 결정값인 레이블 데이터로 모델을 학습한 뒤, 별도의 테스트 데이터 세트에서 미지의 레이블을 예측 
  - 이를 위해 별도로 주어진 데이터를 테스트 데이터 세트로 지칭해야 함
  - ```train_test_split()``` 함수를 통해 데이터 분할

### **2-2. 학습용/평가용 데이터 분할**
- ```train_test_split()``` 함수를 활용

  ```
  train_test_split(feature, target, test_size, # random_state)
  ```
- 학습 데이터로 학습된 모델이 얼마나 뛰어난 성능을 가지는지 평가하려면 테스트 데이터 세트가 필요 -> 반드시 분리 필요
- ```test_size``` 파라미터를 통해 전체 데이터 중 테스트 데이터로 사용할 비율을 설정할 수 있음
- 학습용/테스트용 피처/라벨 데이터를 각각 반환해 줌

### **2-3. 모델링 & 학습**
- 모델 객체 생성
- 모델 학습: ```model.fit(X_train, y_train)```

### **2-4. 예측**
- 모델을 이용한 예측: ```model.predict(X_test)```

### **2-5. 평가**
- 여러 평가 지표 중 **정확도**를 활용할 수 있음
- 정확도(accuracy)
  - 예측 결과가 실제 레이블 값과 얼마나 정확하게 맞는지를 평가하는 지표
  - 사이킷런에서는 ```accuracy_score()``` 함수를 활용
  ```accuracy_score(y_test, pred)```
  
### **📌 전체 프로세스**
<img src = "https://user-images.githubusercontent.com/98953721/228325552-c05f2cea-d6d7-4753-90a1-00a474b5444d.png" width = 600 height = 250>

# **3. 사이킷런의 기반 프레임워크 익히기**
## **3-1. Estimator 이해, fit() & predict() 메소드**
### ● Estimator 클래스**
- 지도학습의 모든 알고리즘을 구현한 클래스
- 분류 알고리즘: ```Classifier``` + 회귀 알고리즘: ```Regressor```
- 사이킷헌은 ML 모델 학습을 위해 ```fit()```을, 학습된 모델의 예측을 위해 ```predict()``` 메서드를 제공함
- 비지도학습 알고리즘의 경우에도 대부분 ```fit()```과 ```transform()```을 적용
  - ```fit()```: 입력 데이터의 형태에 맞춰 데이터를 변환하기 위한 사전 구조를 맞추는 작업
  - ```transform()```: 입력 데이터의 차원 변환, 클러스터링, 피처 추출 등의 실제 작업 수행
    - fit()과 transform()을 결합한 ``fit_transform()``` 메서드도 제공함
- ```cross_val_score()```과 같은 evaluation 함수나 ```GridSearchCV```와 같은 하이퍼 파라미터 튜닝을 지원하는 클래스의 경우 Estimator를 인자로 받음
  - 해당 함수 내에서 **Estimator 객체**의 ```fit()```, ```predict()```을 호출해 평가/hyper parameter tuning 수행

## **3-2. 사이킷런의 주요 모듈**
<img src = "https://user-images.githubusercontent.com/98953721/228576023-1ffbb5f8-d0dc-49fc-9d6f-041e4b1384f0.png" width = 600 height = 200>
<img src = "https://user-images.githubusercontent.com/98953721/228576273-3943a2c9-da1a-4e8e-a88e-68c38f4b0eaf.png" width = 600 height = 700>

## **3-3. 내장된 예제 데이터 세트**
- 분류, 회귀, 클러스터링 등을 연습하기 위한 예제 데이터 세트가 존재
- 사이킷런에 내장된 데이터 세트는 주로 **딕셔너리** 형태를 띔
  - 딕셔너리의 키: data, target, target_name, feature_names, DESCR
    - ```data```: 피처의 데이터 세트, ndarray 타입
    - ```target```: 분류 - 레이블 값/ 회귀 - 숫자 결과값 데이터 세트, ndarray 타입
    - ```target_names```: 개별 레이블의 이름, ndarray 또는 list 타입
    - ```feature_names```: 피처의 이름, ndarray 또는 list 타입
    - ```DESCR```: 데이터 세트에 대한 설명/ 각 피처의 설명, string 타입

# **4. Model Selection 모듈**
- ```sklearn.model_selection``` 모듈
  - 학습 데이터와 테스트 데이터 세트를 분리
  - 교차 검증 분할 및 평가
  - **Estimator**의 하이퍼 파라미터를 튜닝하기 위한 다양한 함수와 클래스

## **4-1. 학습/테스트 데이터 세트 분리**
- 학습과 예측을 **동일한** 데이터 세트로 수행하는 경우 예측 정확도가 거의 100%가 나옴
  - 시험문제를 외워서 푸는 꼴..
> 예측을 수행하는 데이터 세트는 학습을 수행한 학습용 데이터 세트가 아닌 전용 **테스트 데이터** 세트여야 함
- ```sklearn.train_test_split()``` 함수 활용
  - Parameters>
    - feature dataset, label dataset
    - test_size
      - 전체 데이터에서 테스트 데이터 세트 크기를 얼마로 샘플링할 것인가를 결정
      - default: 0.25
    - train_size
      - 전체 데이터에서 학습용 데이터 세트 크기를 얼마로 샘플링할 것인가를 결정
      - test_size를 설정하면 자동으로 계산됨 -> 잘 사용되지 x
    - shuffle
      - 데이터를 분리하기 전에 데이터를 미리 섞을지를 결정
      - default = True
      - 데이터를 분산시켜서 좀 더 효율적인 학습 및 테스트 데이터 세트를 만드는 데 사용
    - random_state
      - 호출할 때마다 동일한 학습/테스트용 데이터 세트를 생성하기 위해 주어지는 난수 값
      - random_state를 지정하지 않으면 수행할 때마다 다른 학습/테스트용 데이터가 생성됨
  - **튜플** 형태의 반환값
    - 학습용 feature, 테스트용 feature, 학습용 label, 테스트용 label
    
## **4-2. 교차 검증(Cross Validatino)**
- 과적합(Overfitting)
  - 모델이 학습 데이터에만 과도하게 최적화되어, 실제 예측을 다른 데이터로 수행할 경우 예측 성능이 과도하게 떨어지는 것
  - **고정된** 학습 데이터와 테스트 데이터로 평가를 하다 보면 테스트 데이터에만 최적의 성능을 발휘할 수 있도록 편향된 모델이 생성되는 경우가 발생할 가능성이 있음
> 교차 검증 활용

- 교차 검증(Cross Validation)
  - 데이터 편중을 막기 위해 별도의 **여러 세트**로 구성된 학습 데이터 세트와 검증 데이터 세트에서 학습과 평가를 수행하는 것
  - 각 세트에서 수행한 평가 결과에 따라 하이퍼 파라미터 튜닝 등의 **모델 최적화**를 쉽게 진행할 수 있음
- 대부분의 ML 알고리즘은 **교차 검증 기반**으로 1차 평가를 한 뒤에 최종적으로 테스트 데이터 세트를 적용해 평가하는 프로세스
  - 테스트 데이터 세트 외에 별도의 **검증 데이터 세트**를 두어 최종 평가 이전에 학습된 모델을 다양하게 평가하는 데 사용함

<img src = "https://user-images.githubusercontent.com/98953721/228590810-fca4a83a-514f-48c3-9a5f-d238cb569643.png" width = 600 height = 250>
  
### **● K-Fold 교차 검증**
- K개의 데이터 폴드 세트를 만들어서 K번만큼 각 폴드 세트에 학습과 검증 평가를 반복적으로 수행하는 방법
<img src = "https://user-images.githubusercontent.com/98953721/228595186-99a30c52-ac13-4430-9314-89d40df1af4b.png" width = 600 height = 300>

- ```split()``` 함수를 호출해 전체 데이터 세트를 분리함
  - 학습용/검증용 데이터로 분할할 수 있는 **인덱스**를 반환
  - 실제로 데이터 추출은 반환된 인덱스를 기반으로 **직접** 개발자가 수행해야 함
  
### **● Stratified K-fold**
- 불균형한(imbalanced) 분포도를 가진 레이블(결정 클래스) 데이터 집합을 위한 K-Fold 방식
  - 특정 레이블 값이 특이하게 많거나 매우 적어서 값의 분포가 한쪽으로 치우친 상태
- K-fold로 랜덤하게 학습/테스트 세트의 인덱스를 고르더라도 레이블 값의 비율을 제대로 반영하지 못하는 경우가 쉽게 발생함
  - 특정 label에 대해 전혀 학습을 하지 못하는 문제가 발생
  - 데이터의 특성을 반영하기 위해 원본 데이터와 유사하게 레이블 값으 분포를 **유지**하는 것이 중요함
- StratifiedKFold의 경우 원본 데이터의 **레이블 분포**를 먼저 고려한 뒤 해당 분포와 동일하게 학습/검증 데이터 세트를 분배
  - split() 메서드에 **레이블 데이터 세트** 또한 필요함
- 분류 문제에서 데이터가 **왜곡된** 분포를 가지는 경우 **Stratified K-fold**를 사용하는 것이 권장됨
  - 회귀의 결정값은 이산형이 아닌 연속형이기에 결정값별로 분포를 정하는 것이 딱히 의미가 있지는 x

### **● cross_val_score()**
- 교차 검증의 일련의 과정을 한꺼번에 수행해주는 API
  - 내부에서 Estimator를 ```학습(fit)```, ```예측(prediction)```, ```평가(estimation)```시켜 줌
- API 선언 형태
  ```Python
  cross_val_score(estimator, X, y = None, scoring = None, cv = None, n_jobs = 1,
                verbose = 0, fit_params = None, pre_dispatch = '2 * n_jobs')
  ```
  - estimator: 사이킷런의 분류(Classifier) 또는 회귀(Regressor) 알고리즘
  - X: 피처 데이터 세트
  - y: 레이블 데이터 세트
  - scoring: 예측 성능 평가 지표
  - cv: 교차 검증 폴드 수
- cv로 지정된 횟수만큼 scoring 파라미터로 지정된 평가 지표로 평가 결괏값을 **배열**로 반환
  - 이후 **평균**을 적용해 평가 수치로 활용
  - 하지만, **하나**의 평가 지표만 적용 가능함
- Stratified K-fold 방식으로 레이블 값의 분포에 따라 학습/테스트 세트를 분할
  - 회귀의 경우 K-Fold 방식으로 분할(<- Stratified 방식을 적용할 수 없어서)

cf> **● cross_validate()**  
- **여러 개**의 평가 지표를 반환할 수 있음
- 학습 데이터에 대한 성능 평가 지표와 수행 시간도 같이 제공

## **4-3. GridSearchCV**
- 교차 검증과 최적 하이퍼 파라미터 튜닝을 한 번에 수행할 수 있도록 해주는 API
  - 파라미터의 집합을 만들고 이를 순차적으로 적용하면서 최적화 수행
- 데이터 세트를 cross-validation을 위한 학습/테스트 세트로 자동으로 분할한 뒤 하이퍼 파라미터 그리드에 기술된 모든 파라미터를 순차적으로 적용해 최적의 하이퍼 파라미터를 탐색
- 동시에 순차적으로 파라미터를 테스트하므로 시간이 오래 걸린다는 단점은 존재
- Parameters>
  <img src = "https://user-images.githubusercontent.com/98953721/228611657-4962b9be-b013-4598-a7a1-9c1f0b580d85.png" width = 700 height = 250>
- GridSearchCV 객체의 ```fit(train_data)``` 메서드를 수행하면 학습 데이터를 ```cv```에 기술된 fold 세트로 분할해 ```param_grid```에 기술된 하이퍼 파라미터를 순차적으로 변경하면서 학습/평가를 수행하고, 그 결과를 ```cv_results_``` 속성에 기록
- ```cv_results_```
  - GridSearchCV의 결과 세트
  - 딕셔러니 평태로 key 값과 리스트 형태의 value 값을 가짐
- 주요 칼럼별 의미>
  - params: 수행할 때마다 적용된 개별 하이퍼 파라미터 값
  - rank_test_score
    - 하이퍼 파라미터별로 성능이 좋은 score 순위를 나타냄
    - 1이 가장 뛰어난 순위이며, 이때의 파라미터가 최적의 파라미터임
  - mean_test_score: 개별 파라미터별로 CV의 폴딩 테스트 세트에 대해 총 수행한 평가의 평균값

- 최고 성능을 나타낸 하이퍼 파라미터의 값과 그때의 평가 결과 값이 각각 ```best_params_```, ```best_score_``` 속성에 기록됨
