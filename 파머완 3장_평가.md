# **0. 성능 평가 지표(Evaluation Metric)**
- 머신러닝 모델은 여러 가지 방법으로 예측 성능을 평가할 수 있음
- 모델이 분류 모델이냐 회귀 모델이냐에 따라 여러 종류로 나뉨
  - 회귀: 대부분 실제값과 예측값의 **오차 평균값**에 기반
  - 분류: 정확도(accuracy), 오차 행렬(confusion matrix), 정밀도(precision), 재현율(recall), F1-score, ROC-AUC

※ 해당 Chapter에서는 주로 ```분류``` 모델의 평가 지표를 다룬다.

# **1. 정확도(Accuracy)**
- 실제 데이터에서 예측 데이터가 얼마나 같은지를 판단하는 지표

<img src = "https://user-images.githubusercontent.com/98953721/231069958-d68345ca-8427-4833-b761-b21c00b58ee1.png" width = 400 height = 80>

- 문제점> **데이터의 구성**에 따라 ML 모델의 성능을 왜곡할 수 있음
  - 이진 분류 문제에서 비율이 **높은** 값(class)으로 무조건 예측하면 예측 성능이 좋게 나온다. 
  - 불균형한(imbalanced) 레이블 값 분포에서 모델의 성능을 판단할 경우, 적합한 평가 지표가 아님
    - 많은 값으로 무조건 찍으면(?) 정확도가 높게 나올 수 있음
- 정확도가 가지는 분류 평가 지표로서의 한계점을 극복하기 위해 여러 가지 분류 지표와 함께 사용됨
  - 오차 행렬 등

# **2. 오차 행렬(Confusion Matrix)**
- 학습된 분류 모델이 예측 수행 시 얼마나 헷갈리고(confused) 있는지를 함께 보여주는 지표
  - 이진 분류의 예측 오류가 얼마인지와 더불어 어떠한 유형의 예측 오류가 발생하고 있는지를 함께 나타내는 지표
- 4분면 행렬에서 **실제** 레이블 클래스 값과 **예측** 레이블 클래스 값이 어떠한 유형을 가지고 매핑되는지를 나타냄
<img src = "https://user-images.githubusercontent.com/98953721/231238980-4d98b6d1-39ed-41e5-a9c2-c49dc4009fb9.png" width = 500 height = 300>

- 사이킷런의 ```confusion_matrix()``` API 활용
  - confusion_matrix(actual, pred) 형식
  - [[TN, FP],  
     [FN, TP]] 형식으로 출력됨
- 오차 행렬의 값들을 조합하여 Classifier의 성능을 측정할 수 있는 주요 지표인 ```정확도(accuracy)```, ```정밀도(precision)```, ```재현율(recall)``` 값을 알 수 있음

# **3. 정밀도와 재현율**
- 양성(positive/ 불균형 데이터에서는 주로 **적은** 값) 데이터 세트의 예측 성능에 좀 더 초점을 맞춘 평가 지표
- 정밀도(precision)
  - 예측을 positive로 한 대상 중에서 예측과 실제 값이 positive로 일치한 데이터의 비율
  - ```TP/(FP+TP)```
  - 실제 positive인 데이터 예측을 negative로 잘못 판단하게 되면 업무상 큰 영향이 발생하는 경우 정밀도가 중요 지표로 작용함(ex> 스팸 메일 분류)
  - 사이킷런의 ```precision_score()``` 활용
  
- 재현율(recall, 민감도, TPR)
  - 실제 값이 positive인 대상 중에 예측과 실제 값이 positive로 일치한 데이터의 비율
  - ```TP/(FN+TP)```
  - 실제 positive 양성 데이터를 negative로 잘못 판단 시 업무상 큰 영향이 발생하는 경우 재현율이 중요 지표로 작용함(ex> 암 판단 모델, 금융 사기 적발 모델)
  - 사이킷런의 ```recall_score()``` 활용
  
 
- 재현율과 정밀도는 서로 **보완적인** 지표로 분류의 성능을 평가하는 데 적용됨
  - 가장 좋은 성능 평가는 재현율과 정밀도 **모두** 높은 수치를 얻는 것

### **3-1. 정밀도/재현율 트레이드오프**
- 분류의 **결정 임계값(threshold)** 을 조정하여 정밀도 또는 재현율의 수치를 높일 수 있음
  - 이진 분류에서는 일반적으로 0.5로 설정하고 해당 값보다 확률이 크면 positive, 작으면 negative로 결정
  - But 정밀도와 재현율은 **상호 보완적**인 평가 지표
  - 어느 한쪽을 강제로 높이면 다른 하나의 수치는 떨어지기 쉬움
- 사이킷런의 분류 알고리즘은 예측 데이터가 특정 레이블에 속하는지를 계산하기 위해 먼저 개별 레이블 별로 **결정 확률**을 구함 
  - 이후 예측 확률이 **큰** 레이블 값으로 최종 예측
  
- ```sklearn.predict_proba()```
  - 개별 데이터 별로 예측 확률을 반환하는 메서드
  - 학습이 완료된 사이킷런 Classifier 객체에서 호출 가능
  - 테스트 피처 데이터 세트를 파라미터로 입력 시 테스트 피처 레코드의 개별 클래스 예측 **확률**을 반환
  - Return> [0에 대한 예측 확률, 1에 대한 예측 확률]

- ```predict()``` 메소드는 ```predict_proba()```을 기반으로 함
- 임계값을 낮추면 재현율 값이 올라가고(FN 감소), 정밀도가 떨어짐(FP 증가)
  - 사이킷런의 ```precision_recall_curve()```를 통해 정밀도와 재현율을 얻을 수 있음
  - 위의 API를 활용하여 정밀도와 재현율 곡선을 시각화 할 수 있음
  
### **3-2. 정밀도와 재현율의 맹점**
- ```positive``` 예측의 임계값이 변경됨에 따라 정밀도와 재현율의 수치가 변경됨
  - 이 두 개의 수치를 **상호 보완**할 수 있는 수준에서 적용되어야 함
- **정밀도 = 100%**  
  - 확실한 기준이 되는 경우만 positive로 예측, 나머지는 모두 negative로 예측
- **재현율 = 100%**
  - 모든 데이터를 양성이라고 예측
> 정밀도와 재현율의 수치가 적절하게 조합돼 분류의 종합적인 성능 평가에 사용될 수 있는 평가 지표가 요구됨

# **4. F1 스코어**
- 정밀도와 재현율을 결합한 지표
<img src = "https://user-images.githubusercontent.com/98953721/231258249-3e4f896c-b5fe-418b-8737-fce5fa11df6b.png" width = 600 height = 100>

- 사이킷런의 ```f1_score()``` 메서드 활용

# **5. ROC 곡선과 AUC**
- ```FPR```(False Positive Rate)이 변할 때 ```TPR```(True Positive Rate, = 재현율)이 어떻게 변하는지를 나타내는 곡선
  - FPR을 X축으로, TPR을 Y축으로 잡아 FPR의 변화에 따른 TPR의 변화를 파악
  - 임곗값을 1부터 0까지 변화시키면서 FPR을 구하고 이 FPR 값의 변화에 따른 TPR 값을 구하는 것
- 민감도 & 특이성
  - 민감도(TNR): 실제값 positive가 정확히 예측돼야 하는 수준, TP/(FN + TP)
  - 특이성(TNR): 실제값 negative가 정확히 예측돼야 하는 수준, FP/(FP + TN)
- FPR = FP/(FP+TN) = 1 - TNR = 1 - 특이성
- ROC 곡선 해석
  - 대각선 직선은 **랜덤** 수준의 이진 분류의 ROC 직선(AUC = 0.5)
  - ROC 곡선이 가운데 직선에 가까울수록 성능이 떨어지고, 멀어질수록 성능이 뛰어난 것임
- 사이킷런의 ```roc_curve(y_true, y_score)``` API 활용
  - 반환값: fpr, tpr, 임계값

- 일반적으로 분류의 성능 **지표**로는 ROC 곡선 면적에 기반한 AUC 값으로 결정
  - AUC(Area Under Curve)
    - ROC 곡선 밑의 면적을 구한 것
    - 일반적으로 1에 가까울수록 좋은 수치
    - 가운데 직선(랜덤 분류)에서 멀어지고 왼쪽 상단 모서리 쪽으로 가파르게 곡선이 이동할수록 직사각형에 가까운 곡선이 되어 면적이 1에 가까워짐 => 좋은 ROC-AUC 성능 수치
    
